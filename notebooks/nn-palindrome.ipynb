{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "RANDOM_SEED = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Palindrome Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_string(length):\n",
    "    return ''.join(np.random.choice(list('abcdefghijklmnopqrstuvwxyz'), length))\n",
    "\n",
    "\n",
    "def generate_palindrome(length):\n",
    "    half_length = length // 2\n",
    "    half_string = generate_random_string(half_length)\n",
    "    if length % 2 == 0:\n",
    "        return half_string + half_string[::-1]\n",
    "    else:\n",
    "        return half_string + np.random.choice(list('abcdefghijklmnopqrstuvwxyz')) + half_string[::-1]\n",
    "    \n",
    "\n",
    "def generate_dataset(num_samples, string_lengths):\n",
    "    data = []\n",
    "    num_samples_per_length = num_samples // len(string_lengths)\n",
    "    for length in string_lengths:\n",
    "        for _ in range(num_samples_per_length):\n",
    "            if np.random.rand() > 0.5:\n",
    "                string = generate_random_string(length)\n",
    "                label = 1\n",
    "            else:\n",
    "                string = generate_palindrome(length)\n",
    "                label = 0\n",
    "            data.append([string, label])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Manual Palindrome Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for 'aba':  0.0\n",
      "Output for 'abb':  2.0\n",
      "Output for 'cba':  2.0\n",
      "Output for 'racecar':  0.0\n",
      "Output for 'saippuakivikauppias':  0.0\n"
     ]
    }
   ],
   "source": [
    "class CustomTokenizer:\n",
    "    def __init__(self):\n",
    "        # Define the special tokens\n",
    "        self.tokens = list(string.ascii_lowercase)\n",
    "        self.token_to_id = {token: i for i, token in enumerate(self.tokens)}\n",
    "        self.id_to_token = {i: token for token, i in enumerate(self.tokens)}\n",
    "        self.vocab = set(self.tokens)\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.max_word_length = 200\n",
    "    \n",
    "    def to_matrix(self, word):\n",
    "        rows = len(word)\n",
    "        cols = len(self.vocab)\n",
    "        matrix = torch.zeros((rows, cols), dtype=torch.float32)\n",
    "        for i, char in enumerate(word):\n",
    "            matrix[i, self.token_to_id[char]] = 1.0\n",
    "        return matrix\n",
    "    \n",
    "class PalindromeNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PalindromeNetwork, self).__init__()\n",
    "        self.tokenizer = CustomTokenizer() \n",
    "        self.IPrime = torch.flip(torch.eye(self.tokenizer.max_word_length), [0])\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        word_len = len(x)\n",
    "        P = self.tokenizer.to_matrix(x)\n",
    "        d = torch.norm(P - self.IPrime[-1*word_len:, :word_len].matmul(P), p=\"fro\")\n",
    "        return d\n",
    "    \n",
    "net = PalindromeNetwork()\n",
    "\n",
    "print(\"Output for 'aba': \", net(\"aba\").item())\n",
    "print(\"Output for 'abb': \", net(\"abb\").item())\n",
    "print(\"Output for 'cba': \", net(\"cba\").item())\n",
    "print(\"Output for 'racecar': \", net(\"racecar\").item())\n",
    "print(\"Output for 'saippuakivikauppias': \", net(\"saippuakivikauppias\").item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn Reverse Identity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/7], Loss: 0.0261\n",
      "Epoch [2/7], Loss: 0.0075\n",
      "Epoch [3/7], Loss: 0.0074\n",
      "Epoch [4/7], Loss: 0.0074\n",
      "Epoch [5/7], Loss: 0.0074\n",
      "Epoch [6/7], Loss: 0.0073\n",
      "Epoch [7/7], Loss: 0.0073\n"
     ]
    }
   ],
   "source": [
    "class CustomTokenizer:\n",
    "    def __init__(self):\n",
    "        # Define the special tokens\n",
    "        self.tokens = list(string.ascii_lowercase)\n",
    "        self.token_to_id = {token: i for i, token in enumerate(self.tokens)}\n",
    "        self.id_to_token = {i: token for token, i in enumerate(self.tokens)}\n",
    "        self.vocab = set(self.tokens)\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.max_word_length = 7\n",
    "    \n",
    "    def to_matrix(self, word):\n",
    "        rows = len(word)\n",
    "        cols = len(self.vocab)\n",
    "        matrix = torch.zeros((rows, cols), dtype=torch.float32)\n",
    "        for i, char in enumerate(word):\n",
    "            matrix[i, self.token_to_id[char]] = 1.0\n",
    "        return matrix\n",
    "    \n",
    "class PalindromeNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PalindromeNetwork, self).__init__()\n",
    "        self.tokenizer = CustomTokenizer() \n",
    "        self.IPrime = nn.Parameter(torch.zeros(self.tokenizer.max_word_length,self.tokenizer.max_word_length))\n",
    "\n",
    "    def forward(self, P):\n",
    "        word_len = P.shape[0]\n",
    "        d = torch.norm(P - self.IPrime[-1*word_len:, :word_len].matmul(P), p=\"fro\")\n",
    "        d = nn.functional.tanh(d)\n",
    "        return d\n",
    "\n",
    "dataset = generate_dataset(10000, [3,4,5])\n",
    "tokenizer = CustomTokenizer()\n",
    "X = []\n",
    "for row in dataset:\n",
    "    X.append([tokenizer.to_matrix(row[0]), row[1]])\n",
    "\n",
    "\n",
    "# Training loop\n",
    "model = PalindromeNetwork()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "num_epochs = 7\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for data in X:\n",
    "        inputs, label = data\n",
    "        label = torch.tensor([label], dtype=torch.float32)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(X):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.46 -0.    0.    0.    0.54  0.    0.  ]\n",
      " [ 0.15  0.08  0.    0.92 -0.15  0.    0.  ]\n",
      " [-0.03 -0.03  1.    0.03  0.03  0.    0.  ]\n",
      " [ 0.02  1.02 -0.   -0.02 -0.02  0.    0.  ]\n",
      " [ 1.08  0.06 -0.   -0.06 -0.08  0.    0.  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17fcfa490>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.IPrime.detach().numpy().round(2))\n",
    "plt.imshow(model.IPrime.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0002, grad_fn=<TanhBackward0>)\n",
      "tensor(0.8384, grad_fn=<TanhBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model(tokenizer.to_matrix(\"abbba\")))\n",
    "print(model(tokenizer.to_matrix(\"abbbba\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
